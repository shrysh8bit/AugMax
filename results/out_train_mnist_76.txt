dataset MNIST     img size 28
loss str Lambda10.0
attack str fat-1-untargeted-10-0.1
saving to ./runs/MNIST/fat-1-untargeted-10-0.1_Lambda10.0_e200-b4000_sgd-lr0.1-m0.9-wd0.0005_cos
1. Running on rank 0.
Namespace(Lambda=10.0, alpha=0.1, attacker='fat', aug_severity=1, batch_size=4000, data_root_path='./data', dataset='MNIST', ddp=False, ddp_backend='nccl', decay='cos', decay_epochs=[100, 150], deepaug=False, dist_url='tcp://localhost:23456', epochs=200, gpu='0', lr=0.1, mixture_depth=1, mixture_width=1, model='MNIST', momentum=0.9, node_id=0, num_nodes=2, num_workers=16, opt='sgd', resume=False, save_root_path='./runs/', steps=10, targeted=False, tau=1, test_batch_size=1000, wd=0.0005, widen_factor=2)
2. in gpu id == 0
ddp False
3. train batch size 4000   num workers 16
4. MNIST data loader
5. Loading dataset MNIST
6. Len of data: clean 54000    augmax 6000
6. type of augmax data <class 'torch.utils.data.dataset.Subset'>
7. type of augmax data <class 'augmax_modules.augmax.AugMaxDataset'>
7. Data loading complete
8. in main fn -> MNIST data len Train 60000   & val 10000
9. Starting dataloader
9. batch size train 4000     test 1000
10. data loaders complete
11. Creating attack class fat
   Temp attacker <class 'utils.attacks.FriendlyAugMaxAttack'>
12. End of attk class
13. Augmix module start
augmix model <class 'augmax_modules.augmax.AugMixModule'> 
    Augmix augmax module create stop
Epoch 0-0 | Train | Loss: 2.3094 (2.3067, 0.0027), SA: 0.0918, RA: 0.0910
False
Epoch 0 | Validation | Time: 34.7036 | lr: 0.1 | SA: 0.5986
Epoch 1-0 | Train | Loss: 2.1684 (2.1140, 0.0543), SA: 0.3230, RA: 0.3173
False
Epoch 1 | Validation | Time: 27.5716 | lr: 0.09999383162408304 | SA: 0.6260
Epoch 2-0 | Train | Loss: 1.9057 (1.6830, 0.2228), SA: 0.4555, RA: 0.4558
False
Epoch 2 | Validation | Time: 27.4608 | lr: 0.09997532801828658 | SA: 0.6948
Epoch 3-0 | Train | Loss: 1.7642 (1.4574, 0.3067), SA: 0.5533, RA: 0.5363
False
Epoch 3 | Validation | Time: 27.6799 | lr: 0.09994449374809851 | SA: 0.7037
Epoch 4-0 | Train | Loss: 1.6724 (1.3411, 0.3313), SA: 0.5928, RA: 0.5995
False
Epoch 4 | Validation | Time: 27.3702 | lr: 0.09990133642141359 | SA: 0.7409
Epoch 5-0 | Train | Loss: 1.6154 (1.2660, 0.3494), SA: 0.6123, RA: 0.6123
False
Epoch 5 | Validation | Time: 27.5955 | lr: 0.09984586668665642 | SA: 0.7677
Epoch 6-0 | Train | Loss: 1.5158 (1.1493, 0.3665), SA: 0.6555, RA: 0.6478
False
Epoch 6 | Validation | Time: 27.5270 | lr: 0.09977809823015402 | SA: 0.7796
Epoch 7-0 | Train | Loss: 1.4845 (1.1282, 0.3562), SA: 0.6730, RA: 0.6698
False
Epoch 7 | Validation | Time: 27.7479 | lr: 0.09969804777275901 | SA: 0.7839
Epoch 8-0 | Train | Loss: 1.4367 (1.0634, 0.3733), SA: 0.6783, RA: 0.6745
False
Epoch 8 | Validation | Time: 27.5815 | lr: 0.09960573506572391 | SA: 0.8031
Epoch 9-0 | Train | Loss: 1.3556 (0.9720, 0.3837), SA: 0.6990, RA: 0.7045
False
Epoch 9 | Validation | Time: 27.5618 | lr: 0.09950118288582789 | SA: 0.8185
Epoch 10-0 | Train | Loss: 1.2910 (0.9070, 0.3840), SA: 0.7248, RA: 0.7235
False
Epoch 10 | Validation | Time: 27.3844 | lr: 0.09938441702975691 | SA: 0.8300
Epoch 11-0 | Train | Loss: 1.2598 (0.8526, 0.4071), SA: 0.7240, RA: 0.7218
False
Epoch 11 | Validation | Time: 27.6910 | lr: 0.09925546630773871 | SA: 0.8281
Epoch 12-0 | Train | Loss: 1.2695 (0.8579, 0.4116), SA: 0.7240, RA: 0.7325
False
Epoch 12 | Validation | Time: 27.6018 | lr: 0.09911436253643445 | SA: 0.8355
Epoch 13-0 | Train | Loss: 1.2143 (0.8003, 0.4140), SA: 0.7465, RA: 0.7375
False
Epoch 13 | Validation | Time: 27.6455 | lr: 0.0989611405310883 | SA: 0.8422
Epoch 14-0 | Train | Loss: 1.1846 (0.7705, 0.4140), SA: 0.7605, RA: 0.7610
False
Epoch 14 | Validation | Time: 27.5700 | lr: 0.09879583809693739 | SA: 0.8511
Epoch 15-0 | Train | Loss: 1.1244 (0.7155, 0.4089), SA: 0.7720, RA: 0.7695
False
Epoch 15 | Validation | Time: 27.3899 | lr: 0.09861849601988384 | SA: 0.8670
Epoch 16-0 | Train | Loss: 1.0930 (0.6878, 0.4053), SA: 0.7883, RA: 0.7910
False
Epoch 16 | Validation | Time: 27.3685 | lr: 0.09842915805643157 | SA: 0.8664
Epoch 17-0 | Train | Loss: 1.0681 (0.6569, 0.4113), SA: 0.7970, RA: 0.7903
False
Epoch 17 | Validation | Time: 27.7272 | lr: 0.09822787092288993 | SA: 0.8678
Epoch 18-0 | Train | Loss: 1.0204 (0.6347, 0.3858), SA: 0.7983, RA: 0.7975
False
Epoch 18 | Validation | Time: 27.7634 | lr: 0.09801468428384717 | SA: 0.8804
Epoch 19-0 | Train | Loss: 1.0606 (0.6520, 0.4086), SA: 0.7923, RA: 0.8035
False
Epoch 19 | Validation | Time: 27.5880 | lr: 0.09778965073991652 | SA: 0.8811
Epoch 20-0 | Train | Loss: 1.0291 (0.6165, 0.4126), SA: 0.8155, RA: 0.8108
False
Epoch 20 | Validation | Time: 27.3073 | lr: 0.0975528258147577 | SA: 0.8883
Epoch 21-0 | Train | Loss: 0.9891 (0.5735, 0.4156), SA: 0.8240, RA: 0.8160
False
Epoch 21 | Validation | Time: 27.4213 | lr: 0.09730426794137728 | SA: 0.8830
Epoch 22-0 | Train | Loss: 0.9658 (0.5732, 0.3926), SA: 0.8253, RA: 0.8235
False
Epoch 22 | Validation | Time: 27.3564 | lr: 0.09704403844771128 | SA: 0.8643
Epoch 23-0 | Train | Loss: 0.9470 (0.5538, 0.3932), SA: 0.8188, RA: 0.8165
False
Epoch 23 | Validation | Time: 27.5577 | lr: 0.09677220154149338 | SA: 0.8952
Epoch 24-0 | Train | Loss: 0.9864 (0.5799, 0.4065), SA: 0.8258, RA: 0.8230
False
Epoch 24 | Validation | Time: 27.2519 | lr: 0.09648882429441258 | SA: 0.8875
Epoch 25-0 | Train | Loss: 0.8696 (0.5167, 0.3529), SA: 0.8373, RA: 0.8388
False
Epoch 25 | Validation | Time: 27.4566 | lr: 0.09619397662556435 | SA: 0.9009
Epoch 26-0 | Train | Loss: 0.9379 (0.5360, 0.4019), SA: 0.8448, RA: 0.8358
False
Epoch 26 | Validation | Time: 27.0481 | lr: 0.09588773128419906 | SA: 0.8931
Epoch 27-0 | Train | Loss: 0.9112 (0.5322, 0.3790), SA: 0.8410, RA: 0.8355
False
Epoch 27 | Validation | Time: 27.3425 | lr: 0.09557016383177226 | SA: 0.8949
Epoch 28-0 | Train | Loss: 0.9061 (0.5060, 0.4001), SA: 0.8543, RA: 0.8478
False
Epoch 28 | Validation | Time: 27.1605 | lr: 0.09524135262330098 | SA: 0.9007
Epoch 29-0 | Train | Loss: 0.8866 (0.4740, 0.4126), SA: 0.8545, RA: 0.8520
False
Epoch 29 | Validation | Time: 27.4513 | lr: 0.09490137878803079 | SA: 0.8959
Epoch 30-0 | Train | Loss: 0.8752 (0.4739, 0.4014), SA: 0.8613, RA: 0.8595
False
Epoch 30 | Validation | Time: 27.3496 | lr: 0.0945503262094184 | SA: 0.9076
Epoch 31-0 | Train | Loss: 0.8848 (0.4732, 0.4117), SA: 0.8498, RA: 0.8525
False
Epoch 31 | Validation | Time: 27.5290 | lr: 0.0941882815044347 | SA: 0.8967
Epoch 32-0 | Train | Loss: 0.8461 (0.4489, 0.3972), SA: 0.8610, RA: 0.8560
False
Epoch 32 | Validation | Time: 27.2943 | lr: 0.09381533400219319 | SA: 0.9037
Epoch 33-0 | Train | Loss: 0.8529 (0.4590, 0.3939), SA: 0.8600, RA: 0.8575
False
Epoch 33 | Validation | Time: 27.5998 | lr: 0.09343157572190958 | SA: 0.8997
Epoch 34-0 | Train | Loss: 0.8493 (0.4495, 0.3999), SA: 0.8650, RA: 0.8568
False
Epoch 34 | Validation | Time: 27.3310 | lr: 0.0930371013501972 | SA: 0.9101
Epoch 35-0 | Train | Loss: 0.8528 (0.4599, 0.3928), SA: 0.8560, RA: 0.8518
False
Epoch 35 | Validation | Time: 27.5200 | lr: 0.09263200821770463 | SA: 0.9120
Epoch 36-0 | Train | Loss: 0.8127 (0.4195, 0.3932), SA: 0.8728, RA: 0.8698
False
Epoch 36 | Validation | Time: 27.5116 | lr: 0.09221639627510078 | SA: 0.9165
Epoch 37-0 | Train | Loss: 0.8275 (0.4186, 0.4089), SA: 0.8635, RA: 0.8585
False
Epoch 37 | Validation | Time: 27.3962 | lr: 0.09179036806841355 | SA: 0.9077
Epoch 38-0 | Train | Loss: 0.8213 (0.4036, 0.4177), SA: 0.8800, RA: 0.8755
False
Epoch 38 | Validation | Time: 27.5059 | lr: 0.09135402871372812 | SA: 0.9054
Epoch 39-0 | Train | Loss: 0.8175 (0.4294, 0.3881), SA: 0.8520, RA: 0.8493
False
Epoch 39 | Validation | Time: 27.6153 | lr: 0.0909074858712512 | SA: 0.9207
Epoch 40-0 | Train | Loss: 0.7923 (0.4010, 0.3913), SA: 0.8773, RA: 0.8790
False
Epoch 40 | Validation | Time: 27.3291 | lr: 0.09045084971874741 | SA: 0.9113
Epoch 41-0 | Train | Loss: 0.7839 (0.3880, 0.3960), SA: 0.8695, RA: 0.8640
False
Epoch 41 | Validation | Time: 27.4482 | lr: 0.08998423292435458 | SA: 0.9069
Epoch 42-0 | Train | Loss: 0.7616 (0.3704, 0.3913), SA: 0.8703, RA: 0.8663
False
Epoch 42 | Validation | Time: 27.5324 | lr: 0.08950775061878455 | SA: 0.9169
Epoch 43-0 | Train | Loss: 0.7546 (0.3789, 0.3757), SA: 0.8780, RA: 0.8795
False
Epoch 43 | Validation | Time: 27.6044 | lr: 0.08902152036691653 | SA: 0.9203
Epoch 44-0 | Train | Loss: 0.7176 (0.3456, 0.3720), SA: 0.8848, RA: 0.8790
False
Epoch 44 | Validation | Time: 28.1755 | lr: 0.08852566213878951 | SA: 0.9156
Epoch 45-0 | Train | Loss: 0.7665 (0.3836, 0.3828), SA: 0.8768, RA: 0.8758
False
Epoch 45 | Validation | Time: 30.1546 | lr: 0.0880202982800016 | SA: 0.9329
Epoch 46-0 | Train | Loss: 0.7427 (0.3742, 0.3685), SA: 0.8835, RA: 0.8800
False
Epoch 46 | Validation | Time: 27.4175 | lr: 0.08750555348152303 | SA: 0.9229
Epoch 47-0 | Train | Loss: 0.7440 (0.3489, 0.3951), SA: 0.8908, RA: 0.8828
False
Epoch 47 | Validation | Time: 27.8202 | lr: 0.08698155474893052 | SA: 0.9357
Epoch 48-0 | Train | Loss: 0.7098 (0.3520, 0.3578), SA: 0.8890, RA: 0.8833
False
Epoch 48 | Validation | Time: 30.2268 | lr: 0.08644843137107061 | SA: 0.9261
Epoch 49-0 | Train | Loss: 0.7273 (0.3525, 0.3748), SA: 0.8900, RA: 0.8838
False
Epoch 49 | Validation | Time: 27.3690 | lr: 0.08590631488815947 | SA: 0.9331
Epoch 50-0 | Train | Loss: 0.7357 (0.3708, 0.3650), SA: 0.8863, RA: 0.8815
False
Epoch 50 | Validation | Time: 27.7888 | lr: 0.0853553390593274 | SA: 0.9263
Epoch 51-0 | Train | Loss: 0.7050 (0.3356, 0.3694), SA: 0.8915, RA: 0.8853
False
Epoch 51 | Validation | Time: 30.1653 | lr: 0.08479563982961574 | SA: 0.9405
Epoch 52-0 | Train | Loss: 0.6900 (0.3326, 0.3575), SA: 0.9050, RA: 0.8955
False
Epoch 52 | Validation | Time: 27.2396 | lr: 0.08422735529643446 | SA: 0.9232
Epoch 53-0 | Train | Loss: 0.6838 (0.3385, 0.3453), SA: 0.8858, RA: 0.8765
False
Epoch 53 | Validation | Time: 27.2508 | lr: 0.08365062567548869 | SA: 0.9359
Epoch 54-0 | Train | Loss: 0.7116 (0.3491, 0.3624), SA: 0.8895, RA: 0.8840
False
Epoch 54 | Validation | Time: 27.5205 | lr: 0.08306559326618261 | SA: 0.9397
Epoch 55-0 | Train | Loss: 0.6405 (0.3217, 0.3189), SA: 0.9053, RA: 0.8958
False
Epoch 55 | Validation | Time: 27.2878 | lr: 0.0824724024165092 | SA: 0.9245
Epoch 56-0 | Train | Loss: 0.6802 (0.3413, 0.3389), SA: 0.8928, RA: 0.8885
False
Epoch 56 | Validation | Time: 27.2626 | lr: 0.0818711994874345 | SA: 0.9331
Epoch 57-0 | Train | Loss: 0.6328 (0.3135, 0.3193), SA: 0.8968, RA: 0.8920
False
Epoch 57 | Validation | Time: 27.4909 | lr: 0.08126213281678528 | SA: 0.9256
